{
    "docs": [
        {
            "location": "/", 
            "text": "Parallec is a fast parallel async HTTP/SSH/TCP/Ping client java library. Scalably aggregate and handle API responses \nanyway\n and send it \nanywhere\n by writing \n20 lines\n of code. Response handler with context enables you conduct scalable API calls, then pass aggregated data anywhere to elastic search, kafka, MongoDB, graphite, memcached, etc. \n\n\n\n\nGet Started\n\n\nMaven\n\n\ndependency\n\n    \ngroupId\nio.parallec\n/groupId\n\n    \nartifactId\nparallec-core\n/artifactId\n\n    \nversion\n0.9.0\n/version\n\n\n/dependency\n\n\n\n\n\nGradle\n\n\ncompile 'io.parallec:parallec-core:0.9.0'\n\n\n\n\n10 Line Example\n\n\nimport io.parallec.core.*;\nimport java.util.Map;\n\nParallelClient pc = new ParallelClient(); \npc.prepareHttpGet(\n).setTargetHostsFromString(\nwww.google.com www.ebay.com www.yahoo.com\n)\n.execute(new ParallecResponseHandler() {\n    public void onCompleted(ResponseOnSingleTask res,\n        Map\nString, Object\n responseContext) {\n        System.out.println( res.toString() );  }\n});\n\n\n\n\n\n\nMore Sample Applications\n.\n\n\nSet Target Hosts\n from list, string, line by line text, json path, cms query from local or remote URLs.\n\n\nFull Documentation\n\n\nJavadoc\n\n\n\n\nUse Cases\n\n\n\n\nScalable web server monitoring, management, and configuration push, ping check.\n\n\nAsset / server status discovery, remote task execution in agent-less(parallel SSH) or agent based (parallel HTTP/TCP) method.\n\n\nScalable API aggregation and processing with flexible destination with your favorate message queue / storage / alert engine.\n\n\nOrchestration and work flows on multiple web servers. \n\n\nParallel different requests with controlled concurrency to a single server. \n\n\n\n\nFeatures\n\n\nParallec means \nParalle\nl \nC\nlient, and is pronounced as \"Para-like\". Parallec is built on Akka actors and Async HTTP Client / Netty / Jsch.  The library focuses on HTTP while also enables scalable communication over SSH/Ping/TCP.\n\n\n90%+ Test coverage\n assures you always find an example of each of feature.\n\n\n\n\nExceedingly intuitive\n interface with builder pattern similar to that in \nAsync HTTP Client\n, but handles concurrency behind the scenes.\n\n\nGeneric response handler with context\n. Enable total freedom of processing each response your way. Process and aggregate data \nanywhere\n to Kafka, Redis, Elastic Search, mongoDB, CMS and etc.  \n\n\nFlexible on when to invoke the handler\n:  before (in worker thread) or after the aggregation (in master/manager thread).\n\n\nFlexible Input of target hosts\n: Input target hosts from a list, string, JSON Path from local files or a remote URL\n\n\nScalable and fast\n, \ninfinitely scalable\n with built-in \nConcurrency control\n.\n\n\nAuto-progress polling\n to enable task level concurrency with \nAsync API\n for long jobs and  orchestrations.\n\n\nRequest template\n to handle non-uniform requests.\n\n\nConvenient single place handling success and failure cases\n. Handle in a single function where you can get the response including the actual response if success; or stacktrace and error details if failures.\n\n\nCapacity aware task scheduler\n helps you to auto queue up and fire tasks when capacity is insufficient. (e.g. submit consecutively 5 tasks each hitting 100K websites with default concurrency will result in a queue up)\n\n\nFine-grained task progress tracking\n helps you track the the progress each individual task status. Of a parallel task on 1000 target hosts, you may check status on any single host task, and percentage progress on how many are completed.\n\n\nFine-grained task cancelation\n on whole/individual request level. Of a parallel task on 1000 target hosts, you may cancel a subset of target hosts or cancel the whole parallel task anytime.\n\n\nStatus-code-aggregation\n is provided out of the box.\n\n\nParallel Ping\n supports both InetAddress.reachable ICMP (requires root) and Process based ping with retries.  Performance testing shows it is \n 67% faster\n than best-effort tuned FPing on pinging on 1500 targets. (2.7 vs 4.5 sec)\n\n\nParallel SSH\n supports both key and password based login and task cancellation.\n\n\nParallel TCP\n supports idle timeout based channel closes.\n\n\n\n\nMotivation\n\n\n\n\nFlexible response handling and immediate processing embedded in other applications.\n\n\nHandle async APIs with auto progress polling for task level concurrency control.\n\n\nSupport of other protocols, and \nmore\n..\n\n\n\n\nWith the feedbacks, lessons, and improvements from the past year of internal usage and open source of \nREST Commander\n, we now made the core of REST Commander as an easy to use standalone library. We added \n15+ new\n features, rewritten 70%+ of the code, with \n90%+ test coverage\n for confident usage and contribution. This time we also structure it better so that most internal development can be directly made here.\n\n\nWatch Parallec in Action\n\n\nWatch Demo\n: Parallec Aggregates 100 websites status with 20 lines of code.\n\n\n\n\nPerformance\n\n\nNote that speed varies based on network speed, API response time, the slowest servers, and concurrency settings.\n\n\nHTTP\n\n\nWe conducted remote task execution API on 3,000 servers with response aggregated to elastic search, visualized within 15 seconds, by writing 25 lines of code.\n\n\nWith another faster API, calls to 8,000 servers in the same datacenter with response aggregated in memory in 12 seconds. \n\n\nPing\n\n\nParallec 2.7 seconds vs FPing 4.5 seconds on 1500 servers. Parallec is 67% faster than \nFPing\n (after best-effort tuning : -i 1 -r 0 v3.12)  of pinging 1500 servers while getting the same ping results.  While FPing consistently crashing (seg fault) when it pings 2000 or more servers,  Parallec pings 8000 servers within 11.8 seconds with breeze.\n\n\nAs usual, don't rely on these numbers and perform your own benchmarks.\n\n\nCompare Parallec vs REST Commander vs ThreadPools+Async Client\n\n\n\n\n\n\n\n\nFeatures\n\n\nParallec\n\n\nREST Commander\n\n\nThread Pools + Async Client\n\n\n\n\n\n\n\n\n\n\nEmbedded library with intuitive builder pattern interface\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nReady to use application with GUI wizard based request submission and response aggregation\n\n\nNo\n\n\nYes\n\n\nNo\n\n\n\n\n\n\nSimple concurrency control not limited by thread size\n\n\nYes\n\n\nYes\n\n\nNo\n\n\n\n\n\n\nImmediate response handler without waiting all response return\n\n\nYes\n\n\nNo\n\n\nYes\n\n\n\n\n\n\nCapacity aware task scheduler and global capacity control\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nTotal freedom of response processing and API aggregation: Pluggable and generic response handler and response context\n\n\nYes\n\n\nNo\n\n\nNo*\n\n\n\n\n\n\n1 line plugin to enable SSL Client auth\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\n90% Test Coverage\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nLoad target hosts from CMS query, JSON Path, text, list, string from URL/local\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nTask level concurrency and orchestration for Async APIs: auto polling task progress\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nTask level configuration on timeout and replacing Async HTTP Client\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nAsync and sync task control with progress polling and cancellation\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nScalable Parallel SSH with password and key based login\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nProven scalability and speed on 100,000+ target hosts in Production environment\n\n\nYes\n\n\nYes\n\n\nNo\n\n\n\n\n\n\nGeneric request template with variable replacement for sending different requests to same/different target hosts\n\n\nYes\n\n\nYes\n\n\nNo\n\n\n\n\n\n\nScalable Ping with Retries\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nScalable TCP with idle timeout\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nFlexible handler location at either worker (in parallel) or manager thread\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nOut-of-the-box two-level response aggregation on status code\n\n\nYes\n\n\nYes\n\n\nNo\n\n\n\n\n\n\nConfigurable response log trimming on intervals\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\nCancel task on a list of target hosts\n\n\nYes\n\n\nNo\n\n\nNo\n\n\n\n\n\n\n\n\nPlugins\n\n\nSSL Client Auth Plugin\n\n\nAuthors\n\n\nParallec is served to you by \nYuanteng (Jeff) Pei\n and \nTeng Song\n, \nCloud Infrastructure \n Platform Services (CIPS)\n at eBay Inc. \n\n\nCredits \n Acknowledgement\n\n\n\n\nWe thanks our manager \nAndy Santosa\n, project manager \nMarco Rotelli\n, \nCloud Infrastructure \n Platform Services (CIPS)\n and legal for the big support on this project and the open source effort.\n\n\nThe auto-progress polling is inspired by \nlightflow\n.\n\n\nWe thank \nopenpojo\n and the author Osman Shoukry for his help on making the openpojo more accessible for us to use in our project.\n\n\nWe thank \nAsyncHttpClient\n and Stephane Landelle for guidance.\n\n\n\n\nContributions\n\n\nAny helpful feedback is more than welcome. This includes feature requests, bug reports, pull requests, constructive feedback, and etc.\n\n\nLicenses\n\n\nCode licensed under Apache License v2.0\n\n\n\u00a9 2015 eBay Software Foundation", 
            "title": "Overview and Setup"
        }, 
        {
            "location": "/#features", 
            "text": "Parallec means  Paralle l  C lient, and is pronounced as \"Para-like\". Parallec is built on Akka actors and Async HTTP Client / Netty / Jsch.  The library focuses on HTTP while also enables scalable communication over SSH/Ping/TCP.  90%+ Test coverage  assures you always find an example of each of feature.   Exceedingly intuitive  interface with builder pattern similar to that in  Async HTTP Client , but handles concurrency behind the scenes.  Generic response handler with context . Enable total freedom of processing each response your way. Process and aggregate data  anywhere  to Kafka, Redis, Elastic Search, mongoDB, CMS and etc.    Flexible on when to invoke the handler :  before (in worker thread) or after the aggregation (in master/manager thread).  Flexible Input of target hosts : Input target hosts from a list, string, JSON Path from local files or a remote URL  Scalable and fast ,  infinitely scalable  with built-in  Concurrency control .  Auto-progress polling  to enable task level concurrency with  Async API  for long jobs and  orchestrations.  Request template  to handle non-uniform requests.  Convenient single place handling success and failure cases . Handle in a single function where you can get the response including the actual response if success; or stacktrace and error details if failures.  Capacity aware task scheduler  helps you to auto queue up and fire tasks when capacity is insufficient. (e.g. submit consecutively 5 tasks each hitting 100K websites with default concurrency will result in a queue up)  Fine-grained task progress tracking  helps you track the the progress each individual task status. Of a parallel task on 1000 target hosts, you may check status on any single host task, and percentage progress on how many are completed.  Fine-grained task cancelation  on whole/individual request level. Of a parallel task on 1000 target hosts, you may cancel a subset of target hosts or cancel the whole parallel task anytime.  Status-code-aggregation  is provided out of the box.  Parallel Ping  supports both InetAddress.reachable ICMP (requires root) and Process based ping with retries.  Performance testing shows it is   67% faster  than best-effort tuned FPing on pinging on 1500 targets. (2.7 vs 4.5 sec)  Parallel SSH  supports both key and password based login and task cancellation.  Parallel TCP  supports idle timeout based channel closes.", 
            "title": "Features"
        }, 
        {
            "location": "/#motivation", 
            "text": "Flexible response handling and immediate processing embedded in other applications.  Handle async APIs with auto progress polling for task level concurrency control.  Support of other protocols, and  more ..   With the feedbacks, lessons, and improvements from the past year of internal usage and open source of  REST Commander , we now made the core of REST Commander as an easy to use standalone library. We added  15+ new  features, rewritten 70%+ of the code, with  90%+ test coverage  for confident usage and contribution. This time we also structure it better so that most internal development can be directly made here.", 
            "title": "Motivation"
        }, 
        {
            "location": "/#watch-parallec-in-action", 
            "text": "Watch Demo : Parallec Aggregates 100 websites status with 20 lines of code.", 
            "title": "Watch Parallec in Action"
        }, 
        {
            "location": "/#performance", 
            "text": "Note that speed varies based on network speed, API response time, the slowest servers, and concurrency settings.  HTTP  We conducted remote task execution API on 3,000 servers with response aggregated to elastic search, visualized within 15 seconds, by writing 25 lines of code.  With another faster API, calls to 8,000 servers in the same datacenter with response aggregated in memory in 12 seconds.   Ping  Parallec 2.7 seconds vs FPing 4.5 seconds on 1500 servers. Parallec is 67% faster than  FPing  (after best-effort tuning : -i 1 -r 0 v3.12)  of pinging 1500 servers while getting the same ping results.  While FPing consistently crashing (seg fault) when it pings 2000 or more servers,  Parallec pings 8000 servers within 11.8 seconds with breeze.  As usual, don't rely on these numbers and perform your own benchmarks.", 
            "title": "Performance"
        }, 
        {
            "location": "/#compare-parallec-vs-rest-commander-vs-threadpoolsasync-client", 
            "text": "Features  Parallec  REST Commander  Thread Pools + Async Client      Embedded library with intuitive builder pattern interface  Yes  No  No    Ready to use application with GUI wizard based request submission and response aggregation  No  Yes  No    Simple concurrency control not limited by thread size  Yes  Yes  No    Immediate response handler without waiting all response return  Yes  No  Yes    Capacity aware task scheduler and global capacity control  Yes  No  No    Total freedom of response processing and API aggregation: Pluggable and generic response handler and response context  Yes  No  No*    1 line plugin to enable SSL Client auth  Yes  No  No    90% Test Coverage  Yes  No  No    Load target hosts from CMS query, JSON Path, text, list, string from URL/local  Yes  No  No    Task level concurrency and orchestration for Async APIs: auto polling task progress  Yes  No  No    Task level configuration on timeout and replacing Async HTTP Client  Yes  No  No    Async and sync task control with progress polling and cancellation  Yes  No  No    Scalable Parallel SSH with password and key based login  Yes  No  No    Proven scalability and speed on 100,000+ target hosts in Production environment  Yes  Yes  No    Generic request template with variable replacement for sending different requests to same/different target hosts  Yes  Yes  No    Scalable Ping with Retries  Yes  No  No    Scalable TCP with idle timeout  Yes  No  No    Flexible handler location at either worker (in parallel) or manager thread  Yes  No  No    Out-of-the-box two-level response aggregation on status code  Yes  Yes  No    Configurable response log trimming on intervals  Yes  No  No    Cancel task on a list of target hosts  Yes  No  No", 
            "title": "Compare Parallec vs REST Commander vs ThreadPools+Async Client"
        }, 
        {
            "location": "/#plugins", 
            "text": "SSL Client Auth Plugin", 
            "title": "Plugins"
        }, 
        {
            "location": "/#authors", 
            "text": "Parallec is served to you by  Yuanteng (Jeff) Pei  and  Teng Song ,  Cloud Infrastructure   Platform Services (CIPS)  at eBay Inc.", 
            "title": "Authors"
        }, 
        {
            "location": "/#credits-acknowledgement", 
            "text": "We thanks our manager  Andy Santosa , project manager  Marco Rotelli ,  Cloud Infrastructure   Platform Services (CIPS)  and legal for the big support on this project and the open source effort.  The auto-progress polling is inspired by  lightflow .  We thank  openpojo  and the author Osman Shoukry for his help on making the openpojo more accessible for us to use in our project.  We thank  AsyncHttpClient  and Stephane Landelle for guidance.", 
            "title": "Credits &amp; Acknowledgement"
        }, 
        {
            "location": "/#contributions", 
            "text": "Any helpful feedback is more than welcome. This includes feature requests, bug reports, pull requests, constructive feedback, and etc.", 
            "title": "Contributions"
        }, 
        {
            "location": "/#licenses", 
            "text": "Code licensed under Apache License v2.0  \u00a9 2015 eBay Software Foundation", 
            "title": "Licenses"
        }, 
        {
            "location": "/api-overview/", 
            "text": "API Overview\n\n\nOur goal is simply to execute a task of firing a list of uniform or non-uniform HTTP/TCP/SSH/PING requests to a list of target hosts, then call the user defined handler to handler each of the responses.  We define such a task with its metadata as \nParallelTask\n.\n\n\nLet's review the sample example again for a HTTP POST call to 2 target hosts. \nParallelClient\n is the starting point of parallec, which returns a \nParallelTaskBuilder\n by a \nprepare*()\n function (e.g.  prepareHttpGet(), prepareHttpPost(),  prepareSsh(),  preparePing()  etc). The ParallelTaskBuilder is to build a specific \nParallelTask\n with certain metadata.\n\n\nParallelClient pc = new ParallelClient(); \npc.prepareHttpPost(\n/executeCmds\n)\n.setHeaders(new ParallecHeader().addPair(\ncontent-type\n, \napplication/json\n))\n.setPort(10050)\n.setConcurrency(1000)\n.setBody( \n{  \\\ncmd\\\n:\\\n  df -h; \\\n}\n)\n.setTargetHostsFromString(\nserver1.host.com, server2.host.com\n)\n.execute( new ParallecResponseHandler() {\n    @Override\n    public void onCompleted(ResponseOnSingleTask res,\n            Map\nString, Object\n responseContext) {\n        System.out.println( res.toString() );  }\n});\npc.releaseExternalResources();\n\n\n\n\nPlease first review these \nKey Classes\n below.We will then break down on each component of a \"ParallelTask\", and give more details of the functions in \"ParallelTaskBuilder\".\n\n\nThese APIs can be generally categorized by the following:\n\n\n\n\nGenerate and submit Parallel Task (with class \nParallelClient \n ParallelTaskBuilder\n) : \n\n\nAPIs to set general ParalleTask attributes such as concurrency, whether to enable scheduler, whether to save response/logs, configs to set actor timeouts.  \n\n\nAPIs to set protocol specific metadata on each protocol of HTTP/TCP/SSH/Ping. Such as Http port, URL, entity body. These parameters are used by the loaded async http client.\n\n\nAPIs to set target hosts from different sources.\n\n\nAPIs relate to the response handling: set response handler with context, when to call the handler, whether to save responses, and whether to auto write task execution logs. \n\n\n\n\n\n\nTrack ParallelTask status/results and examine responses (with class \nParallelTask\n)\n\n\n\n\nThe above two part are listed as separate sections in this documentation.\n\n\nPlease also review \nParallec Samples\n of list of independent examples to get single executable for parallel executions on each protocol.\n\n\nSupported Protocols\n\n\nParallec currently supports the following protocols.\n\n\n\n\n\n\n\n\nFunction\n\n\nBased Upon\n\n\n\n\n\n\n\n\n\n\nHTTP\n\n\nAsync HTTP Client\n\n\n\n\n\n\nSSH\n\n\nJSch\n\n\n\n\n\n\nPING\n\n\nJDK net\n / Process\n\n\n\n\n\n\nTCP\n\n\nNetty\n\n\n\n\n\n\n\n\nKey Classes and Notations\n\n\nFirst let's review some key class in parallec. You may click the link to read more on their javadocs\n\n\n\n\n\n\n\n\nNotations\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nParallelClient\n\n\nThis is the starting point of parallec, which returns a ParallelTaskBuilder after a \nprepare*()\n function. The ParallelTaskBuilder is to build a specific ParallelTask\n\n\n\n\n\n\nParallelTask\n\n\nThe key class represents a onetime execution on multiple requests. It contains all the task and request metadata, target hosts, configs, and the responses.\n\n\n\n\n\n\nParallelTaskBuilder\n\n\nThe key builder to build the parallel task and then execute it after the validation process. During the validation, certain missing parameters will use the default values.\n\n\n\n\n\n\nParallelTaskManager\n\n\nThe class to manage the current running tasks and wait queue (Singleton). generateUpdateExecuteTask() is the key function to execute a ParallelTask.\n\n\n\n\n\n\nTaskRequest\n\n\nThis is the request sent to the operation worker. It contains the actual request that has been replaced if there are variables defined.\n\n\n\n\n\n\nSingleTask\n\n\nIt represents request(s) and response(s) on a single target host. For async API. there could be 1 task submission request followed by \nn\n polling requests sent out.\n\n\n\n\n\n\nResponseOnSingleTask\n\n\nThe final response on a single task. This class also contains the request metadata, and the each polling response. It is available in the response handler's onComplete() function\n\n\n\n\n\n\nResponseOnSingleRequest\n\n\nA single response for each HTTP/SSH/TCP/Ping request.", 
            "title": "API Overview"
        }, 
        {
            "location": "/api-overview/#api-overview", 
            "text": "Our goal is simply to execute a task of firing a list of uniform or non-uniform HTTP/TCP/SSH/PING requests to a list of target hosts, then call the user defined handler to handler each of the responses.  We define such a task with its metadata as  ParallelTask .  Let's review the sample example again for a HTTP POST call to 2 target hosts.  ParallelClient  is the starting point of parallec, which returns a  ParallelTaskBuilder  by a  prepare*()  function (e.g.  prepareHttpGet(), prepareHttpPost(),  prepareSsh(),  preparePing()  etc). The ParallelTaskBuilder is to build a specific  ParallelTask  with certain metadata.  ParallelClient pc = new ParallelClient(); \npc.prepareHttpPost( /executeCmds )\n.setHeaders(new ParallecHeader().addPair( content-type ,  application/json ))\n.setPort(10050)\n.setConcurrency(1000)\n.setBody(  {  \\ cmd\\ :\\   df -h; \\ } )\n.setTargetHostsFromString( server1.host.com, server2.host.com )\n.execute( new ParallecResponseHandler() {\n    @Override\n    public void onCompleted(ResponseOnSingleTask res,\n            Map String, Object  responseContext) {\n        System.out.println( res.toString() );  }\n});\npc.releaseExternalResources();  Please first review these  Key Classes  below.We will then break down on each component of a \"ParallelTask\", and give more details of the functions in \"ParallelTaskBuilder\".  These APIs can be generally categorized by the following:   Generate and submit Parallel Task (with class  ParallelClient   ParallelTaskBuilder ) :   APIs to set general ParalleTask attributes such as concurrency, whether to enable scheduler, whether to save response/logs, configs to set actor timeouts.    APIs to set protocol specific metadata on each protocol of HTTP/TCP/SSH/Ping. Such as Http port, URL, entity body. These parameters are used by the loaded async http client.  APIs to set target hosts from different sources.  APIs relate to the response handling: set response handler with context, when to call the handler, whether to save responses, and whether to auto write task execution logs.     Track ParallelTask status/results and examine responses (with class  ParallelTask )   The above two part are listed as separate sections in this documentation.  Please also review  Parallec Samples  of list of independent examples to get single executable for parallel executions on each protocol.  Supported Protocols  Parallec currently supports the following protocols.     Function  Based Upon      HTTP  Async HTTP Client    SSH  JSch    PING  JDK net  / Process    TCP  Netty", 
            "title": "API Overview"
        }, 
        {
            "location": "/api-overview/#key-classes-and-notations", 
            "text": "First let's review some key class in parallec. You may click the link to read more on their javadocs     Notations  Details      ParallelClient  This is the starting point of parallec, which returns a ParallelTaskBuilder after a  prepare*()  function. The ParallelTaskBuilder is to build a specific ParallelTask    ParallelTask  The key class represents a onetime execution on multiple requests. It contains all the task and request metadata, target hosts, configs, and the responses.    ParallelTaskBuilder  The key builder to build the parallel task and then execute it after the validation process. During the validation, certain missing parameters will use the default values.    ParallelTaskManager  The class to manage the current running tasks and wait queue (Singleton). generateUpdateExecuteTask() is the key function to execute a ParallelTask.    TaskRequest  This is the request sent to the operation worker. It contains the actual request that has been replaced if there are variables defined.    SingleTask  It represents request(s) and response(s) on a single target host. For async API. there could be 1 task submission request followed by  n  polling requests sent out.    ResponseOnSingleTask  The final response on a single task. This class also contains the request metadata, and the each polling response. It is available in the response handler's onComplete() function    ResponseOnSingleRequest  A single response for each HTTP/SSH/TCP/Ping request.", 
            "title": "Key Classes and Notations"
        }, 
        {
            "location": "/submit-task/", 
            "text": "Generate \n Submit Task\n\n\nThe most efficient way to use Parallec is by reviewing the \nexample codes\n.\n\n\nAlso review the \n\n\nAPIs on Request Generation\n\n\nFirst lets check on the ones that are protocol independent. \n\n\n\n\nsetTargetHostsFrom*()\n is critical to set the target hosts, you may check the details on the following section\n\n\nsetConcurrency()\n is important when you want to change how fast/slow to send the requests.\n\n\n\n\nDetails on configs please check \nhere\n.\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nsetTargetHostsFrom*()\n\n\nRequired\n\n\nNo default. Must be set.\n\n\nTo set target host list from a string, list, line by lien text, jsonpath, and cms query from local or remote.\n\n\n\n\n\n\nsetProtocol()\n\n\nOptional\n\n\nHTTP\n\n\nNormally we do not need to set this. When you do prepare*() it is already set.  When it is HTTPS. you will need to set it\n\n\n\n\n\n\nsetConcurrency()\n\n\nOptional\n\n\nconcurrencyDefault  (1000)\n\n\nThe concurrency level. You may send 100,000 requests but send it very slowly.\n\n\n\n\n\n\nsetConfig()\n\n\nOptional\n\n\ndefault values\n\n\nConfigs about various timeout, whether to auto save responses. whether to enable the response. This can set all the task level over writable configurations.\n\n\n\n\n\n\nsetEnableCapacityAware TaskScheduler()\n\n\nOptional\n\n\nfalse: not enabled\n\n\nAfter enabled, can accommodate the traffic.\n\n\n\n\n\n\nasync()\n\n\nOptional\n\n\nfalse, default to sync mode.\n\n\nTo run the parallel task async . You may check if the task is completed later.\n\n\n\n\n\n\n\n\nCapacity aware scheduler\n\n\nWhen enabled, task will be pushed to the wait queue instead of immediate execution. A daemon thread (by newSingleThreadScheduledExecutor) will check every 0.5 second if there is capacity to run a task from the wait queue.\n\n\nThis is useful to protect our application when there are multiple concurrent ParallelTasks, and each has high currency requirement. \n\n\nBy default this scheduler is disabled. This is unnecessary unless there are high load or tasks are submitted without our control (e.g. serve as a server).\n\n\nAPIs on Response Handling\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nhandleInWorker() handleInManager()\n\n\nOptional\n\n\nHandleInManager()\n\n\nPlease check the \nResponse Handler Location\n below for details.\n\n\n\n\n\n\nsetResponseContext()\n\n\nOptional\n\n\nAn empty hashmap\n\n\nUseful when need to pass arbitrary objects from/to the response handler: e.g. pass in an Elastic Search or Kafka Client, or a hashmap to store / process / aggregate the responses.\n\n\n\n\n\n\nexecute()\n\n\nRequired\n\n\nn/a\n\n\nKey function to execute the parallel task. It will first do a validation on required data before the execution.\n\n\n\n\n\n\nsetAutoSaveLogToLocal()\n\n\nOptional\n\n\nFalse\n\n\nWill auto save logs to the local file system. The logs by default are written to path \"userdata/task/logs\" folder. Note that it is user's responsibility to clearn these logs.\n\n\n\n\n\n\nsetSaveResponseToTask()\n\n\nOptional\n\n\nFalse\n\n\nIf true, will save response to the ParallelTask object. In default, only status code is saved.\n\n\n\n\n\n\n\n\nResponse Handler Location\n\n\nThis is about when to call the user defined response handler's onComplete() function. \n\n\n\n\nHandler in manager\n (default): Call response handler in manager (in a sequence after aggregation) Default mode. In this mode, will trigger the user defined response hander after response is passed back from worker to manager. This is the default mode. Be cautious on using long blocking operation in the handler onComplete() function. Because a long operation may block the whole flow  because each response will need to go through here. \n\n\nHandler in worker\n: Call response handler in operation worker (in parallel before aggregation). Handle the user defined onComplete() function in worker before aggregation (handle in parallel). Be cautious on concurrency / lock control if save the response to a common data store. Also when you define the concurrency level, take into account of the time needed to hander the response. \n\n\n\n\nSet Target Hosts\n\n\nParallec provide flexible way to input multiple target hosts from list, string, line by line text, json path, cms query from local or remote urls.\n\n\nCheck the following \n.setTargetHosts*()\n functions to set the target hosts.\n\n\nFrom Java List\n\n\n.setTargetHostsFromList(Arrays.asList(\nwww.jeffpei.com\n, \nwww.restcommander.com\n));\n\n\n\n\nFrom Java String\n\n\nFrom a single string as separate by whitespace.\n\n\n.setTargetHostsFromString(\nwww.jeffpei.com www.restcommander.com\n);\n\n\n\n\nFrom Line by Line Text\n\n\nFrom a local file containing host names line by line. Relative or absolute paths are both supported. \n\n\n.setTargetHostsFromLineByLineText(\nuserdata/sample_target_hosts_top100_old.txt\n,\n                         HostsSourceType.LOCAL_FILE)\n\n\n\n\nAlso, you can set target hosts from such a file from a web URL. (This will use the apache server)\n\n\n.setTargetHostsFromLineByLineText(\nhttp://www.restcommander.com/docs/sample_target_hosts_top100.txt\n,\n                         HostsSourceType.URL)\n\n\n\n\nFrom Json Path\n\n\nJsonPath\n is useful to extract host name list from a json file\n\n\nHere is a sample \njson\n file that contains host names.\n\n\nAs long as seperate by whitespace\n\n\nString jsonPath = \n$.sample.small-target-hosts[*].hostName\n;\n\n.setTargetHostsFromJsonPath(jsonPath,\n                \nhttp://parallec.github.io/userdata/sample_target_hosts_json_path.json\n, HostsSourceType.URL);\n\n\n\n\nYou may also load such jsons from local file system too.\n\n\nFrom YiDB/CMS Query\n\n\nYiDB\n a.k.a CMS (Configuration Manage System internally) may store the cloud topology information.\n\n\nHere is a sample \nCMS Query Result\n that contains host names.\n\n\nParallec will auto load target hosts from CMS query and handles paginations for you.\n\n\npublic final String URL_CMS_QUERY_MULTI_PAGE = \nhttp://parallec.github.io/cms/repositories/cmsdb/branches/main/query/sample_cms_query_results_multi_page_1.json\n;\n\n.setTargetHostsFromCmsQueryUrl(URL_CMS_QUERY_MULTI_PAGE);\n\n\n\n\nTimeout in URLs\n\n\nParallecGlobalConfig defines the timeout using the remote URL to get target hosts. One may change it before usage.\n\n\n/** The url connection connect timeout millis. Used when load target host from URL/CMS*/\npublic static int urlConnectionConnectTimeoutMillis = 6000;\n\n/** The url connection read timeout millis. Used when load target host from URL/CMS*/\npublic static int urlConnectionReadTimeoutMillis = 15000;\n\n\n\n\nAPIs on HTTP\n\n\nMost of the APIs to set HTTP properties are named with \nsetHttp*()\n, except for the setAsyncHttpClient() which overwrite the asyncHttpClient used.\n\n\nSet HTTP Method, URL and Protocol\n\n\n\n\nprepareHttp*() will set the url and HTTP Method. e.g., prepareHttpGet(\"/index.html\")  means to conduct HTTP GET  http://[targethost]:/index.html\n\n\nWhen need to do HTTPS, will do setProtocol(RequestProtocol.HTTPS)\n\n\n\n\nSet HTTP Header\n\n\nHere is the sample code to set HTTP Header with help of ParallecHeader.\n\n\n.setHttpHeaders(new ParallecHeader().addPair(\ncontent-type\n, \napplication/json\n).addPair(\nkey\n, \nvalue\n))\n\n\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nprepareHttp*()\n\n\nRequired\n\n\nn/a\n\n\nThis is the starting point. Will will set the HttpMethod (e.g. GET/POST/PUT/DELETE)  and the url.\n\n\n\n\n\n\nsetHttpHeaders()\n\n\nOptional\n\n\nempty\n\n\nAdd headers using ParallecHeader. Check example above.\n\n\n\n\n\n\nsetHttpEntityBody()\n\n\nOptional\n\n\nempty\n\n\nFor example, a POST body for the request.\n\n\n\n\n\n\nsetHttpPort()\n\n\nOptional\n\n\nport 80\n\n\nSet HTTP port.\n\n\n\n\n\n\nsetHttpPoller Processor()\n\n\nOptional\n\n\nempty\n\n\nSets the HTTP poller processor to handle Async API,  will auto enable the pollable mode with this call. Details check \nhere\n.\n\n\n\n\n\n\nsetAsyncHttpClient()\n\n\nOptional\n\n\nEmbed fast one from the store\n\n\nYou may overwrite the client to your customized one for each task. The default one is the embed fast one from HttpClientStore.\n\n\n\n\n\n\n\n\nAPIs on SSH\n\n\nThe APIs to set SSH properties are named with \nsetSsh*()\n.\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nprepareSsh()\n\n\nRequired\n\n\nn/a\n\n\nStarting point of ssh.  Set protocol as SSH.\n\n\n\n\n\n\nsetSsh CommandLine()\n\n\nRequired\n\n\nn/a\n\n\nThe command flow you would like to execute.\n\n\n\n\n\n\nsetSshPort()\n\n\nOptional\n\n\n22\n\n\nThe SSH Port.\n\n\n\n\n\n\nsetSsh UserName()\n\n\nRequired\n\n\nn/a\n\n\nUser name when login\n\n\n\n\n\n\nsetSsh LoginType()\n\n\nOptional\n\n\nempty\n\n\nThe login is either key or password based.\n\n\n\n\n\n\nsetSshPassword()\n\n\nOptional\n\n\nn/a\n\n\nThe ssh login password.  Will also auto set the login type to password\n\n\n\n\n\n\nsetSsh Connection TimeoutMillis()\n\n\nOptional\n\n\n5000 millisec\n\n\nConnection timeout.  Default to 5000 millisec in global config.\n\n\n\n\n\n\nsetSshPrivKey RelativePath()\n\n\nOptional\n\n\nn/a\n\n\nNote that this path must be relative to the project e.g. \"userdata/fake-privkey.txt\".  This API assumes no passphrase for the private key. Will also auto set the login type to key based.\n\n\n\n\n\n\nsetSshPrivKey RelativePath WtihPassphrase()\n\n\nOptional\n\n\nn/a\n\n\nNote that this path must be relative to the project. argument include a private key path with passphrase. Will also auto set the login type to key based.\n\n\n\n\n\n\n\n\nAPIs on PING\n\n\nThe APIs to set Ping properties are named with \nsetPing*()\n.\n\n\nDetails of the two modes of implementations can be found in \nPingProvider.java\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\npreparePing()\n\n\nRequired\n\n\nn/a\n\n\nStarting point of ssh.  Set protocol as \"Ping\".\n\n\n\n\n\n\nsetPingMode()\n\n\nOptional\n\n\nInetAddress\n\n\nProcess or InetAddress based. Default as InetAddress mode. InetAddress requires Root privilege.\n\n\n\n\n\n\nsetPing TimeoutMillis()\n\n\nOptional\n\n\n500\n\n\nThe timeout in milliseconds.\n\n\n\n\n\n\nsetPing NumRetries()\n\n\nOptional\n\n\n1\n\n\nThe number of retries.\n\n\n\n\n\n\n\n\nAPIs on TCP\n\n\nThe APIs to set TCP properties are named with \nsetTcp*()\n.\n\n\n\n\n\n\n\n\nAPI\n\n\nRequired\n\n\nDefault If Not Set\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nprepareTcp()\n\n\nRequired\n\n\nn/a\n\n\nStarting point of TCP request.  Set protocol as \"TCP\" and the request string.\n\n\n\n\n\n\nsetTcpPort()\n\n\nRequired\n\n\nn/a\n\n\nA port number server listens on.\n\n\n\n\n\n\nsetTcp Connect TimeoutMillis()\n\n\nOptional\n\n\nuse default 2000\n\n\nThe connection timeout in milliseconds.\n\n\n\n\n\n\nsetTcpIdle TimeoutSec()\n\n\nOptional\n\n\nuse default 5\n\n\nThe idle timeout for the channel to close the connection.\n\n\n\n\n\n\nsetTcp ChannelFactory()\n\n\nOptional\n\n\nuse the  default one\n\n\nIf not set, will use the default one in TcpSshPingResourceStore.\n\n\n\n\n\n\n\n\nAPIs on Variable Replacement for Heterogeneous Requests\n\n\nWhen the protocol is HTTP, the request's entity body, request URL, and also the header part can be putting as a \ntemplate\n with variable denoted with \n\"$VariableName\"\n.\n\n\nMore complex replacement samples are available in the \ntest cases\n. \n\n\nDifferent requests to different target hosts\n\n\nHere is the example of hitting 3 different APIs on 3 different servers. \n$JOB_ID\n is the variable being replaced. The API to use is \nsetReplacementVarMapNodeSpecific()\n. Complete sample code is \nhere\n.\n\n\n\n\nhttp://www.parallec.io/job_a.html\n\n\nhttp://www.jeffpei.com/job_b.html\n \n\n\nhttp://www.restsuperman.com/job_c.html\n\n\n\n\nMap\nString, StrStrMap\n replacementVarMapNodeSpecific = new HashMap\nString, StrStrMap\n();\nreplacementVarMapNodeSpecific.put(\nwww.parallec.io\n,\n        new StrStrMap().addPair(\nJOB_ID\n, \njob_a\n));\nreplacementVarMapNodeSpecific.put(\nwww.jeffpei.com\n,\n        new StrStrMap().addPair(\nJOB_ID\n, \njob_b\n));\nreplacementVarMapNodeSpecific.put(\nwww.restcommander.com\n,\n        new StrStrMap().addPair(\nJOB_ID\n, \njob_c\n));\n\npc.prepareHttpGet(\n/$JOB_ID.html\n)\n        .setTargetHostsFromString(\n                \nwww.parallec.io www.jeffpei.com www.restcommander.com\n)\n        .setReplacementVarMapNodeSpecific(replacementVarMapNodeSpecific)\n        .execute(new ParallecResponseHandler() {...}...\n\n\n\n\n\n\nDifferent requests to the same target host\n\n\nHere is the example of hitting 2 different APIs to the same target host. \n$ZIP\n is the variable being replaced. \nsetReplaceVarMapToSingleTargetSingleVar(String variable, List\n replaceList, String uniformTargetHost)\n is the API to use. There are more complex replacements APIs available in javadoc. Complete sample code is \nhere\n.\n\n\n\n\nhttp://www.parallec.io/userdata/sample_weather_48824.txt\n\n\nhttp://www.parallec.io/userdata/sample_weather_95037.txt\n\n\n\n\npc.prepareHttpGet(\n/userdata/sample_weather_$ZIP.txt\n)\n    .setReplaceVarMapToSingleTargetSingleVar(\nZIP\n,\n        Arrays.asList(\n95037\n,\n48824\n), \nwww.parallec.io\n)\n    .setResponseContext(responseContext)\n    .execute(new ParallecResponseHandler() {...}...\n\n\n\n\n\nRegular Expression Response Filter\n\n\nWhen defining the response handler, we provide a very simple regular expression based filter class \nFilterRegex\n to extract strings.\n\n\nFor example: with ResponseOnSingleTask \nres\n, we can apply parse on the response body.\n\n\nString extractedString = new FilterRegex(\n    \n.*\ntd\nJobProgress\n/td\n\\\\s*\ntd\n(.*?)\n/td\n.*\n)\n    .filter(res.getResponseContent());        \n\n\n\n\n\nAsync APIs and Auto Progress Polling\n\n\nMotivation\n\n\nIn many RESTful services today, a job such as \"create compute\", \"download package\" may take indefinite amount of time. And these APIs are normally designed to be asynchronus. They immediately return a \nJob ID\n, by which you can poll for the job progress and check status. To achieve job level concurrency, it is essential to define a \npoller\n, which describes how to poll progress and when to stop as below. Here are the attributes in a poller. Please refer to the \njavadoc\n for more details.\n\n\n\n\nThe regex to get jobId\n\n\nThe regex to get the progress\n\n\nThe progress polling API (a template with the jobId)\n\n\nThe job completion regex\n\n\nThe job failure regex\n\n\nThe polling interval\n\n\n\n\nSample Server\n\n\nPlease check this \nexample\n for complete code. If we have a job submission API that return a job ID, as in this \nsample server\n\n\n//submit job \nHTTP POST: /submitJob return: {\nstatus\n: \n/status/01218499-a5fe-47cf-a0a8-8e9b106c5219\n, \nprogress\n: 0}\n\n//poll progress \nHTTP GET: /status/{JobID}\n\n\n\n\nSample Poller\n\n\n// Initialize the poller\nString pollerType = \nCronusAgentPoller\n;\nString successRegex = \n.*\\\nprogress\\\n\\\\s*:\\\\s*(100).*}\n;\nString failureRegex = \n.*\\\nerror\\\n\\\\s*:\\\\s*(.*).*}\n;\nString jobIdRegex = \n.*\\\n/status/(.*?)\\\n.*\n;\nString progressRegex = \n.*\\\nprogress\\\n\\\\s*:\\\\s*([0-9]*).*}\n;\nint progressStuckTimeoutSeconds = 600;\nint maxPollError = 5;\nlong pollIntervalMillis = 2000L;\nString jobIdPlaceHolder = \n$JOB_ID\n;\nString pollerRequestTemplate = \n/status/\n + jobIdPlaceHolder;\n\nHttpPollerProcessor httpPollerProcessor = new HttpPollerProcessor(\n        pollerType, successRegex, failureRegex, jobIdRegex,\n        progressRegex, progressStuckTimeoutSeconds, pollIntervalMillis,\n        pollerRequestTemplate, jobIdPlaceHolder, maxPollError);\n\n\n\n\nTo enable the poller defined above, simply call \n.setHttpPollerProcessor(httpPollerProcessor)\n when building the task. Parallec will then automatically poll the task progress until it is successful or failure for you, and enable the job level concurrency.", 
            "title": "Generate & Submit Task"
        }, 
        {
            "location": "/submit-task/#generate-submit-task", 
            "text": "The most efficient way to use Parallec is by reviewing the  example codes .  Also review the", 
            "title": "Generate &amp; Submit Task"
        }, 
        {
            "location": "/submit-task/#apis-on-request-generation", 
            "text": "First lets check on the ones that are protocol independent.    setTargetHostsFrom*()  is critical to set the target hosts, you may check the details on the following section  setConcurrency()  is important when you want to change how fast/slow to send the requests.   Details on configs please check  here .     API  Required  Default If Not Set  Details      setTargetHostsFrom*()  Required  No default. Must be set.  To set target host list from a string, list, line by lien text, jsonpath, and cms query from local or remote.    setProtocol()  Optional  HTTP  Normally we do not need to set this. When you do prepare*() it is already set.  When it is HTTPS. you will need to set it    setConcurrency()  Optional  concurrencyDefault  (1000)  The concurrency level. You may send 100,000 requests but send it very slowly.    setConfig()  Optional  default values  Configs about various timeout, whether to auto save responses. whether to enable the response. This can set all the task level over writable configurations.    setEnableCapacityAware TaskScheduler()  Optional  false: not enabled  After enabled, can accommodate the traffic.    async()  Optional  false, default to sync mode.  To run the parallel task async . You may check if the task is completed later.     Capacity aware scheduler  When enabled, task will be pushed to the wait queue instead of immediate execution. A daemon thread (by newSingleThreadScheduledExecutor) will check every 0.5 second if there is capacity to run a task from the wait queue.  This is useful to protect our application when there are multiple concurrent ParallelTasks, and each has high currency requirement.   By default this scheduler is disabled. This is unnecessary unless there are high load or tasks are submitted without our control (e.g. serve as a server).", 
            "title": "APIs on Request Generation"
        }, 
        {
            "location": "/submit-task/#apis-on-response-handling", 
            "text": "API  Required  Default If Not Set  Details      handleInWorker() handleInManager()  Optional  HandleInManager()  Please check the  Response Handler Location  below for details.    setResponseContext()  Optional  An empty hashmap  Useful when need to pass arbitrary objects from/to the response handler: e.g. pass in an Elastic Search or Kafka Client, or a hashmap to store / process / aggregate the responses.    execute()  Required  n/a  Key function to execute the parallel task. It will first do a validation on required data before the execution.    setAutoSaveLogToLocal()  Optional  False  Will auto save logs to the local file system. The logs by default are written to path \"userdata/task/logs\" folder. Note that it is user's responsibility to clearn these logs.    setSaveResponseToTask()  Optional  False  If true, will save response to the ParallelTask object. In default, only status code is saved.     Response Handler Location  This is about when to call the user defined response handler's onComplete() function.    Handler in manager  (default): Call response handler in manager (in a sequence after aggregation) Default mode. In this mode, will trigger the user defined response hander after response is passed back from worker to manager. This is the default mode. Be cautious on using long blocking operation in the handler onComplete() function. Because a long operation may block the whole flow  because each response will need to go through here.   Handler in worker : Call response handler in operation worker (in parallel before aggregation). Handle the user defined onComplete() function in worker before aggregation (handle in parallel). Be cautious on concurrency / lock control if save the response to a common data store. Also when you define the concurrency level, take into account of the time needed to hander the response.", 
            "title": "APIs on Response Handling"
        }, 
        {
            "location": "/submit-task/#set-target-hosts", 
            "text": "Parallec provide flexible way to input multiple target hosts from list, string, line by line text, json path, cms query from local or remote urls.  Check the following  .setTargetHosts*()  functions to set the target hosts.  From Java List  .setTargetHostsFromList(Arrays.asList( www.jeffpei.com ,  www.restcommander.com ));  From Java String  From a single string as separate by whitespace.  .setTargetHostsFromString( www.jeffpei.com www.restcommander.com );  From Line by Line Text  From a local file containing host names line by line. Relative or absolute paths are both supported.   .setTargetHostsFromLineByLineText( userdata/sample_target_hosts_top100_old.txt ,\n                         HostsSourceType.LOCAL_FILE)  Also, you can set target hosts from such a file from a web URL. (This will use the apache server)  .setTargetHostsFromLineByLineText( http://www.restcommander.com/docs/sample_target_hosts_top100.txt ,\n                         HostsSourceType.URL)  From Json Path  JsonPath  is useful to extract host name list from a json file  Here is a sample  json  file that contains host names.  As long as seperate by whitespace  String jsonPath =  $.sample.small-target-hosts[*].hostName ;\n\n.setTargetHostsFromJsonPath(jsonPath,\n                 http://parallec.github.io/userdata/sample_target_hosts_json_path.json , HostsSourceType.URL);  You may also load such jsons from local file system too.  From YiDB/CMS Query  YiDB  a.k.a CMS (Configuration Manage System internally) may store the cloud topology information.  Here is a sample  CMS Query Result  that contains host names.  Parallec will auto load target hosts from CMS query and handles paginations for you.  public final String URL_CMS_QUERY_MULTI_PAGE =  http://parallec.github.io/cms/repositories/cmsdb/branches/main/query/sample_cms_query_results_multi_page_1.json ;\n\n.setTargetHostsFromCmsQueryUrl(URL_CMS_QUERY_MULTI_PAGE);  Timeout in URLs  ParallecGlobalConfig defines the timeout using the remote URL to get target hosts. One may change it before usage.  /** The url connection connect timeout millis. Used when load target host from URL/CMS*/\npublic static int urlConnectionConnectTimeoutMillis = 6000;\n\n/** The url connection read timeout millis. Used when load target host from URL/CMS*/\npublic static int urlConnectionReadTimeoutMillis = 15000;", 
            "title": "Set Target Hosts"
        }, 
        {
            "location": "/submit-task/#apis-on-http", 
            "text": "Most of the APIs to set HTTP properties are named with  setHttp*() , except for the setAsyncHttpClient() which overwrite the asyncHttpClient used.  Set HTTP Method, URL and Protocol   prepareHttp*() will set the url and HTTP Method. e.g., prepareHttpGet(\"/index.html\")  means to conduct HTTP GET  http://[targethost]:/index.html  When need to do HTTPS, will do setProtocol(RequestProtocol.HTTPS)   Set HTTP Header  Here is the sample code to set HTTP Header with help of ParallecHeader.  .setHttpHeaders(new ParallecHeader().addPair( content-type ,  application/json ).addPair( key ,  value ))     API  Required  Default If Not Set  Details      prepareHttp*()  Required  n/a  This is the starting point. Will will set the HttpMethod (e.g. GET/POST/PUT/DELETE)  and the url.    setHttpHeaders()  Optional  empty  Add headers using ParallecHeader. Check example above.    setHttpEntityBody()  Optional  empty  For example, a POST body for the request.    setHttpPort()  Optional  port 80  Set HTTP port.    setHttpPoller Processor()  Optional  empty  Sets the HTTP poller processor to handle Async API,  will auto enable the pollable mode with this call. Details check  here .    setAsyncHttpClient()  Optional  Embed fast one from the store  You may overwrite the client to your customized one for each task. The default one is the embed fast one from HttpClientStore.", 
            "title": "APIs on HTTP"
        }, 
        {
            "location": "/submit-task/#apis-on-ssh", 
            "text": "The APIs to set SSH properties are named with  setSsh*() .     API  Required  Default If Not Set  Details      prepareSsh()  Required  n/a  Starting point of ssh.  Set protocol as SSH.    setSsh CommandLine()  Required  n/a  The command flow you would like to execute.    setSshPort()  Optional  22  The SSH Port.    setSsh UserName()  Required  n/a  User name when login    setSsh LoginType()  Optional  empty  The login is either key or password based.    setSshPassword()  Optional  n/a  The ssh login password.  Will also auto set the login type to password    setSsh Connection TimeoutMillis()  Optional  5000 millisec  Connection timeout.  Default to 5000 millisec in global config.    setSshPrivKey RelativePath()  Optional  n/a  Note that this path must be relative to the project e.g. \"userdata/fake-privkey.txt\".  This API assumes no passphrase for the private key. Will also auto set the login type to key based.    setSshPrivKey RelativePath WtihPassphrase()  Optional  n/a  Note that this path must be relative to the project. argument include a private key path with passphrase. Will also auto set the login type to key based.", 
            "title": "APIs on SSH"
        }, 
        {
            "location": "/submit-task/#apis-on-ping", 
            "text": "The APIs to set Ping properties are named with  setPing*() .  Details of the two modes of implementations can be found in  PingProvider.java     API  Required  Default If Not Set  Details      preparePing()  Required  n/a  Starting point of ssh.  Set protocol as \"Ping\".    setPingMode()  Optional  InetAddress  Process or InetAddress based. Default as InetAddress mode. InetAddress requires Root privilege.    setPing TimeoutMillis()  Optional  500  The timeout in milliseconds.    setPing NumRetries()  Optional  1  The number of retries.", 
            "title": "APIs on PING"
        }, 
        {
            "location": "/submit-task/#apis-on-tcp", 
            "text": "The APIs to set TCP properties are named with  setTcp*() .     API  Required  Default If Not Set  Details      prepareTcp()  Required  n/a  Starting point of TCP request.  Set protocol as \"TCP\" and the request string.    setTcpPort()  Required  n/a  A port number server listens on.    setTcp Connect TimeoutMillis()  Optional  use default 2000  The connection timeout in milliseconds.    setTcpIdle TimeoutSec()  Optional  use default 5  The idle timeout for the channel to close the connection.    setTcp ChannelFactory()  Optional  use the  default one  If not set, will use the default one in TcpSshPingResourceStore.", 
            "title": "APIs on TCP"
        }, 
        {
            "location": "/submit-task/#apis-on-variable-replacement-for-heterogeneous-requests", 
            "text": "When the protocol is HTTP, the request's entity body, request URL, and also the header part can be putting as a  template  with variable denoted with  \"$VariableName\" .  More complex replacement samples are available in the  test cases .   Different requests to different target hosts  Here is the example of hitting 3 different APIs on 3 different servers.  $JOB_ID  is the variable being replaced. The API to use is  setReplacementVarMapNodeSpecific() . Complete sample code is  here .   http://www.parallec.io/job_a.html  http://www.jeffpei.com/job_b.html    http://www.restsuperman.com/job_c.html   Map String, StrStrMap  replacementVarMapNodeSpecific = new HashMap String, StrStrMap ();\nreplacementVarMapNodeSpecific.put( www.parallec.io ,\n        new StrStrMap().addPair( JOB_ID ,  job_a ));\nreplacementVarMapNodeSpecific.put( www.jeffpei.com ,\n        new StrStrMap().addPair( JOB_ID ,  job_b ));\nreplacementVarMapNodeSpecific.put( www.restcommander.com ,\n        new StrStrMap().addPair( JOB_ID ,  job_c ));\n\npc.prepareHttpGet( /$JOB_ID.html )\n        .setTargetHostsFromString(\n                 www.parallec.io www.jeffpei.com www.restcommander.com )\n        .setReplacementVarMapNodeSpecific(replacementVarMapNodeSpecific)\n        .execute(new ParallecResponseHandler() {...}...  Different requests to the same target host  Here is the example of hitting 2 different APIs to the same target host.  $ZIP  is the variable being replaced.  setReplaceVarMapToSingleTargetSingleVar(String variable, List  replaceList, String uniformTargetHost)  is the API to use. There are more complex replacements APIs available in javadoc. Complete sample code is  here .   http://www.parallec.io/userdata/sample_weather_48824.txt  http://www.parallec.io/userdata/sample_weather_95037.txt   pc.prepareHttpGet( /userdata/sample_weather_$ZIP.txt )\n    .setReplaceVarMapToSingleTargetSingleVar( ZIP ,\n        Arrays.asList( 95037 , 48824 ),  www.parallec.io )\n    .setResponseContext(responseContext)\n    .execute(new ParallecResponseHandler() {...}...", 
            "title": "APIs on Variable Replacement for Heterogeneous Requests"
        }, 
        {
            "location": "/submit-task/#regular-expression-response-filter", 
            "text": "When defining the response handler, we provide a very simple regular expression based filter class  FilterRegex  to extract strings.  For example: with ResponseOnSingleTask  res , we can apply parse on the response body.  String extractedString = new FilterRegex(\n     .* td JobProgress /td \\\\s* td (.*?) /td .* )\n    .filter(res.getResponseContent());", 
            "title": "Regular Expression Response Filter"
        }, 
        {
            "location": "/submit-task/#async-apis-and-auto-progress-polling", 
            "text": "Motivation  In many RESTful services today, a job such as \"create compute\", \"download package\" may take indefinite amount of time. And these APIs are normally designed to be asynchronus. They immediately return a  Job ID , by which you can poll for the job progress and check status. To achieve job level concurrency, it is essential to define a  poller , which describes how to poll progress and when to stop as below. Here are the attributes in a poller. Please refer to the  javadoc  for more details.   The regex to get jobId  The regex to get the progress  The progress polling API (a template with the jobId)  The job completion regex  The job failure regex  The polling interval   Sample Server  Please check this  example  for complete code. If we have a job submission API that return a job ID, as in this  sample server  //submit job \nHTTP POST: /submitJob return: { status :  /status/01218499-a5fe-47cf-a0a8-8e9b106c5219 ,  progress : 0}\n\n//poll progress \nHTTP GET: /status/{JobID}  Sample Poller  // Initialize the poller\nString pollerType =  CronusAgentPoller ;\nString successRegex =  .*\\ progress\\ \\\\s*:\\\\s*(100).*} ;\nString failureRegex =  .*\\ error\\ \\\\s*:\\\\s*(.*).*} ;\nString jobIdRegex =  .*\\ /status/(.*?)\\ .* ;\nString progressRegex =  .*\\ progress\\ \\\\s*:\\\\s*([0-9]*).*} ;\nint progressStuckTimeoutSeconds = 600;\nint maxPollError = 5;\nlong pollIntervalMillis = 2000L;\nString jobIdPlaceHolder =  $JOB_ID ;\nString pollerRequestTemplate =  /status/  + jobIdPlaceHolder;\n\nHttpPollerProcessor httpPollerProcessor = new HttpPollerProcessor(\n        pollerType, successRegex, failureRegex, jobIdRegex,\n        progressRegex, progressStuckTimeoutSeconds, pollIntervalMillis,\n        pollerRequestTemplate, jobIdPlaceHolder, maxPollError);  To enable the poller defined above, simply call  .setHttpPollerProcessor(httpPollerProcessor)  when building the task. Parallec will then automatically poll the task progress until it is successful or failure for you, and enable the job level concurrency.", 
            "title": "Async APIs and Auto Progress Polling"
        }, 
        {
            "location": "/track-status/", 
            "text": "Track Status \n Examine Responses\n\n\nOverview\n\n\nBy default Parallec only stores the response status code, but not store response content string. Because we \n\n\nKey Classes\n\n\nThe ParallelTaskBuilder\n.execute(new ParallecResponseHandler()\n returns a \nParallelTask\n object, which we could use to track the status of the task. \n\n\nPlease review the javadoc for the following classes (click to enter).\n\n\n\n\nParallelTask\n\n\nResponseOnSingleTask\n\n\nParallelTaskState\n\n\n\n\nBy default we execute the task in \"synchronous/blocking\" mode, which means after the execution line is completed, the task must be in COMPLETED_WITH_ERROR or COMPLETED_WITHOUT_ERROR \nstate\n.\n\n\nReview Sample Code for Track Task Progress and Response Status Aggregation\n\n\nIn the example below, we make it run asynchronously by setting \nasync()\n, then we use a for loop to check the output. This is useful when frontend ajax call to track the task progress.\n\n\nParallelTaskResult\n\n\nThis is an important member field in ParallelTask.   It is a hashmap which stores the request parameters, host name, ResponseOnSingleTask. Note that by default, the response content/payload is not saved into the ResponseOnSingleTask to save space. User may overwrite this by calling ParallelTaskBuilder.setSaveResponseToTask(true).\n\n\nParallelClient pc = new ParallelClient();\n\nParallelTask task = pc.prepareHttpGet(\n).async()\n        .setConcurrency(500)\n        .setTargetHostsFromLineByLineText(\nuserdata/sample_target_hosts_top100_old.txt\n,\n                 HostsSourceType.LOCAL_FILE)\n        .execute(new ParallecResponseHandler() {\n            @Override\n            public void onCompleted(ResponseOnSingleTask res,\n                    Map\nString, Object\n responseContext) {\n                System.out.println(\nResponose Code:\n\n                        + res.getStatusCode() + \n host: \n\n                        + res.getHost());\n            }\n        });\n\nwhile (!task.isCompleted()) {\n    try {\n        Thread.sleep(100L);\n        System.out.println(String.format(\n                \nPOLL_JOB_PROGRESS (%.5g%%)  PT jobid: %s\n,\n                task.getProgress(), task.getTaskId()));\n        pc.logHealth();\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n}\n\nSystem.out\n.println(\nResult Summary\\n \n\n        + PcStringUtils.renderJson(task\n                .getAggregateResultFullSummary()));\n\nSystem.out\n        .println(\nResult Brief Summary\\n \n\n                + PcStringUtils.renderJson(task\n                        .getAggregateResultCountSummary()));\npc.releaseExternalResources();\n\n\n\n\nResponse Status Code Aggregation\n\n\nAs showed in this example, you may call \n. getAggregateResultCountSummary()\n \n.getAggregateResultFullSummary()\n to get the response status code aggregation.\n\n\nAs shown in this example, as we are in a firewall/proxy controlled place, certain website will timeout\n\n\nTo get Json String: we can use \n\n\nPcStringUtils.renderJson(task\n                    .getAggregateResultCountSummary() )\n\n\n\nTo directly get human readable aggregation String:\n\n\ntask.getAggregatedResultHumanStr()\n\n\n\ngetAggregateResultCountSummary()\n\n\nTo save space, some host names are not displayed here. \n\n\n {\n  \n301 Moved Permanently\n: 17,\n  \n302 Found\n: 9,\n  \n200 OK\n: 58,\n  \n301 TLS Redirect\n: 1,\n  \n302 Moved Temporarily\n: 6,\n  \n404 Not Found\n: 1,\n  \n200 Ok\n: 1,\n  \n301 Redirect\n: 1,\n  \n301 https://www.pinterest.com/\n: 1,\n  \n302 FOUND\n: 1,\n  \nFAIL_GET_RESPONSE: HttpWorker Timedout after 15 SEC (no response but no exception catched). Check URL: may be very slow or stuck.\n: 1\n}\n\n\n\n\n\ngetAggregateResultFullSummary()\n\n\n {\n  \n301 Moved Permanently\n: {\n    \ncount\n: 17,\n    \nset\n: [\n      \nwww.twitter.com\n\n      ...\n\n      \nwww.mail.ru\n\n    ]\n  },\n  \n302 Found\n: {\n    \ncount\n: 9,\n    \nset\n: [\n      \nwww.facebook.com\n,\n        ...\n      \nwww.vk.com\n\n    ]\n  },\n  \n200 OK\n: {\n    \ncount\n: 58,\n    \nset\n: [\n      \nwww.amazon.de\n,\n      \nwww.odnoklassniki.ru\n,\n      \nwww.baidu.com\n,\n      \nwww.uol.com.br\n,\n      \nwww.sohu.com\n,\n      \nwww.ifeng.com\n\n    ]\n  },\n  \n301 TLS Redirect\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.wikipedia.org\n\n    ]\n  },\n  \n302 Moved Temporarily\n: {\n    \ncount\n: 6,\n    \nset\n: [\n      \nwww.imgur.com\n,\n      \nwww.blogger.com\n,\n      \nwww.microsoft.com\n,\n      \nwww.soso.com\n,\n      \nwww.tumblr.com\n,\n      \nwww.weibo.com\n\n    ]\n  },\n  \n404 Not Found\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.googleusercontent.com\n\n    ]\n  },\n  \n200 Ok\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.yandex.ru\n\n    ]\n  },\n  \n301 Redirect\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.yahoo.com\n\n    ]\n  },\n  \n301 https://www.pinterest.com/\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.pinterest.com\n\n    ]\n  },\n  \n302 FOUND\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.instagram.com\n\n    ]\n  },\n  \nFAIL_GET_RESPONSE: HttpWorker Timedout after 15 SEC (no response but no exception catched). Check URL: may be very slow or stuck.\n: {\n    \ncount\n: 1,\n    \nset\n: [\n      \nwww.qq.com\n\n    ]\n  }\n}\n\n\n\n\n\nSample ParallelTask Fields\n\n\n{\n  \nsubmitTime\n: \n2015.10.13.23.29.24.890-0700\n,\n  \nexecuteStartTime\n: \n2015.10.13.23.29.24.964-0700\n,\n  \nexecutionEndTime\n: \n2015.10.13.23.29.25.145-0700\n,\n  \ndurationSec\n: 0.181,\n  \nrequestNum\n: 3,\n  \nrequestNumActual\n: 3,\n  \nresponsedNum\n: 3,\n  \ntaskErrorMetas\n: [],\n  \nresponseContext\n: {},\n  \nstate\n: \nCOMPLETED_WITHOUT_ERROR\n,\n  \ntaskId\n: \nPT_3_20151013232924890_9a72cf3c-ecf\n,\n  ...\n}\n\n\n\n\nSave ParallelTask to Logs\n\n\nBoth will put the logs of of the complete tasks into\n\n\nuserdata/tasklogs/**filename\n\n\n\n\nBefore execution: enabled by \nParallelTaskBuilder.setAutoSaveLogToLocal()\n\n\nAfter getting ParallelTask: call \nParallelTask.saveLogToLocal()\n \n\n\n\n\nSample ParallelTask Results \n\n\nhttp://www.parallec.io/userdata/sample_tasklogs/PT_3_20151013140312854_a8aa7404-515.jsonlog.txt\n\n\n\n\n3 website responses\n: COMPLETED_WITHOUT_ERROR; set as save response back to the task. \n\n\n97 websites task\n: COMPLETED_WITH_ERROR: canceled by user in the middle\n\n\n\n\nWe have plans to add more fields to add to the output.\n\n\nHealth Check\n\n\nFor convenience, JVM Memory usage and Thread infomration can be obtained from the following APIs.\n\n\nParallelClient.logHealth(); //jvm memory as string output\n\nMonitorProvider.getInstance().getLiveThreadCount();\nMonitorProvider.getInstance().getJVMMemoryUsage();", 
            "title": "Track Status & Examine Response"
        }, 
        {
            "location": "/track-status/#track-status-examine-responses", 
            "text": "", 
            "title": "Track Status &amp; Examine Responses"
        }, 
        {
            "location": "/track-status/#overview", 
            "text": "By default Parallec only stores the response status code, but not store response content string. Because we   Key Classes  The ParallelTaskBuilder .execute(new ParallecResponseHandler()  returns a  ParallelTask  object, which we could use to track the status of the task.   Please review the javadoc for the following classes (click to enter).   ParallelTask  ResponseOnSingleTask  ParallelTaskState   By default we execute the task in \"synchronous/blocking\" mode, which means after the execution line is completed, the task must be in COMPLETED_WITH_ERROR or COMPLETED_WITHOUT_ERROR  state .  Review Sample Code for Track Task Progress and Response Status Aggregation  In the example below, we make it run asynchronously by setting  async() , then we use a for loop to check the output. This is useful when frontend ajax call to track the task progress.  ParallelTaskResult  This is an important member field in ParallelTask.   It is a hashmap which stores the request parameters, host name, ResponseOnSingleTask. Note that by default, the response content/payload is not saved into the ResponseOnSingleTask to save space. User may overwrite this by calling ParallelTaskBuilder.setSaveResponseToTask(true).  ParallelClient pc = new ParallelClient();\n\nParallelTask task = pc.prepareHttpGet( ).async()\n        .setConcurrency(500)\n        .setTargetHostsFromLineByLineText( userdata/sample_target_hosts_top100_old.txt ,\n                 HostsSourceType.LOCAL_FILE)\n        .execute(new ParallecResponseHandler() {\n            @Override\n            public void onCompleted(ResponseOnSingleTask res,\n                    Map String, Object  responseContext) {\n                System.out.println( Responose Code: \n                        + res.getStatusCode() +   host:  \n                        + res.getHost());\n            }\n        });\n\nwhile (!task.isCompleted()) {\n    try {\n        Thread.sleep(100L);\n        System.out.println(String.format(\n                 POLL_JOB_PROGRESS (%.5g%%)  PT jobid: %s ,\n                task.getProgress(), task.getTaskId()));\n        pc.logHealth();\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n}\n\nSystem.out\n.println( Result Summary\\n  \n        + PcStringUtils.renderJson(task\n                .getAggregateResultFullSummary()));\n\nSystem.out\n        .println( Result Brief Summary\\n  \n                + PcStringUtils.renderJson(task\n                        .getAggregateResultCountSummary()));\npc.releaseExternalResources();  Response Status Code Aggregation  As showed in this example, you may call  . getAggregateResultCountSummary()   .getAggregateResultFullSummary()  to get the response status code aggregation.  As shown in this example, as we are in a firewall/proxy controlled place, certain website will timeout  To get Json String: we can use   PcStringUtils.renderJson(task\n                    .getAggregateResultCountSummary() )  To directly get human readable aggregation String:  task.getAggregatedResultHumanStr()  getAggregateResultCountSummary()  To save space, some host names are not displayed here.    {\n   301 Moved Permanently : 17,\n   302 Found : 9,\n   200 OK : 58,\n   301 TLS Redirect : 1,\n   302 Moved Temporarily : 6,\n   404 Not Found : 1,\n   200 Ok : 1,\n   301 Redirect : 1,\n   301 https://www.pinterest.com/ : 1,\n   302 FOUND : 1,\n   FAIL_GET_RESPONSE: HttpWorker Timedout after 15 SEC (no response but no exception catched). Check URL: may be very slow or stuck. : 1\n}  getAggregateResultFullSummary()   {\n   301 Moved Permanently : {\n     count : 17,\n     set : [\n       www.twitter.com \n      ...\n\n       www.mail.ru \n    ]\n  },\n   302 Found : {\n     count : 9,\n     set : [\n       www.facebook.com ,\n        ...\n       www.vk.com \n    ]\n  },\n   200 OK : {\n     count : 58,\n     set : [\n       www.amazon.de ,\n       www.odnoklassniki.ru ,\n       www.baidu.com ,\n       www.uol.com.br ,\n       www.sohu.com ,\n       www.ifeng.com \n    ]\n  },\n   301 TLS Redirect : {\n     count : 1,\n     set : [\n       www.wikipedia.org \n    ]\n  },\n   302 Moved Temporarily : {\n     count : 6,\n     set : [\n       www.imgur.com ,\n       www.blogger.com ,\n       www.microsoft.com ,\n       www.soso.com ,\n       www.tumblr.com ,\n       www.weibo.com \n    ]\n  },\n   404 Not Found : {\n     count : 1,\n     set : [\n       www.googleusercontent.com \n    ]\n  },\n   200 Ok : {\n     count : 1,\n     set : [\n       www.yandex.ru \n    ]\n  },\n   301 Redirect : {\n     count : 1,\n     set : [\n       www.yahoo.com \n    ]\n  },\n   301 https://www.pinterest.com/ : {\n     count : 1,\n     set : [\n       www.pinterest.com \n    ]\n  },\n   302 FOUND : {\n     count : 1,\n     set : [\n       www.instagram.com \n    ]\n  },\n   FAIL_GET_RESPONSE: HttpWorker Timedout after 15 SEC (no response but no exception catched). Check URL: may be very slow or stuck. : {\n     count : 1,\n     set : [\n       www.qq.com \n    ]\n  }\n}  Sample ParallelTask Fields  {\n   submitTime :  2015.10.13.23.29.24.890-0700 ,\n   executeStartTime :  2015.10.13.23.29.24.964-0700 ,\n   executionEndTime :  2015.10.13.23.29.25.145-0700 ,\n   durationSec : 0.181,\n   requestNum : 3,\n   requestNumActual : 3,\n   responsedNum : 3,\n   taskErrorMetas : [],\n   responseContext : {},\n   state :  COMPLETED_WITHOUT_ERROR ,\n   taskId :  PT_3_20151013232924890_9a72cf3c-ecf ,\n  ...\n}  Save ParallelTask to Logs  Both will put the logs of of the complete tasks into  userdata/tasklogs/**filename   Before execution: enabled by  ParallelTaskBuilder.setAutoSaveLogToLocal()  After getting ParallelTask: call  ParallelTask.saveLogToLocal()     Sample ParallelTask Results   http://www.parallec.io/userdata/sample_tasklogs/PT_3_20151013140312854_a8aa7404-515.jsonlog.txt   3 website responses : COMPLETED_WITHOUT_ERROR; set as save response back to the task.   97 websites task : COMPLETED_WITH_ERROR: canceled by user in the middle   We have plans to add more fields to add to the output.  Health Check  For convenience, JVM Memory usage and Thread infomration can be obtained from the following APIs.  ParallelClient.logHealth(); //jvm memory as string output\n\nMonitorProvider.getInstance().getLiveThreadCount();\nMonitorProvider.getInstance().getJVMMemoryUsage();", 
            "title": "Overview"
        }, 
        {
            "location": "/configurations/", 
            "text": "Configurations\n\n\nOverview\n\n\n\n\n\n\nParallecGlobalConfig\n: this is the global system config. You can replace the values here before executing them. Different from those settings defined in ParallelTaskConfig, settings here are effective to all executions, and cannot be overwritten for a particular task.\n\n\nParallelTaskConfig\n: Configuration as a member of every ParallecTask. You may overwrite it by setConfig() when build the task. The initial values are set from the \ndefaults\n.\n\n\n\n\nWe recommand you to read the source code (straighforward) to check what you may be able to change.\n\n\nAsync HTTP Client\n\n\n\"HttpClientStore\" (singleton) stores a pair of default embedded fast/slow AsyncHttpClient, and another pair of customized fast/slow AsyncHttpClient. By default the pair of customized ones are just refereces (same as) the embedded ones.\n\n\nWhen you submit a ParallelTask, if you do not set a specific AsyncHttpClient for this session, the default one is the Embedded fast. \n\n\nYou may set your customized client:\n\n\n\n\nJust for one task or a session: when submit the task, setAsyncHttpClient() with your own context/parameters\n\n\nWant to change for all the sessions, you can still do the above way every time you submit the task. Or you could call the following to set the default to be your own customized client to avoid setting it everytime.\n\n\n\n\n HttpClientStore.getInstance().setCustomClientFast(yourClient);\n HttpClientStore.getInstance().setHttpClientTypeCurrentDefault(HttpClientType.CUSTOM_FAST);\n\n\n\n\nTimeout\n\n\n\n\nConnection / Request Timeout, as these are parameters from the Async HTTP Client, you will need to either change them in the global config or replace it in \n\n\ntimeoutInManagerSec and  actorMaxOperationTimeoutSec respectively, controls if the AHC or SSH/TCP/Ping client does not timeout, the actor level timeout in manager (for parallel task) and in the worker. \n\n\n\n\nReduce Verbose Logs\n\n\nIf you find the logs are chatty, please check the global config, there are parameters related to how to reduce the interval.  Current logic is always log first the first K% and the last K% percent, for those in the middle, will log based on the interval. You may overwrite these before submit a ParallelTask.\n\n\nAlso, you may change the log level as a whole.\n\n\n    /** The log response interval. */\n    public static int logResponseInterval = 1;\n\n    /** The log all response after percent. */\n    public static double logAllResponseAfterPercent = 95.0;\n\n    /** The log all response before percent. */\n    public static double logAllResponseBeforePercent = 5.0;\n\n    /** The log all response before init count. */\n    public static int logAllResponseBeforeInitCount = 2;\n\n    /** The log all response if total less than. */\n    public static int logAllResponseIfTotalLessThan = 11;", 
            "title": "Configurations"
        }, 
        {
            "location": "/configurations/#configurations", 
            "text": "", 
            "title": "Configurations"
        }, 
        {
            "location": "/configurations/#overview", 
            "text": "ParallecGlobalConfig : this is the global system config. You can replace the values here before executing them. Different from those settings defined in ParallelTaskConfig, settings here are effective to all executions, and cannot be overwritten for a particular task.  ParallelTaskConfig : Configuration as a member of every ParallecTask. You may overwrite it by setConfig() when build the task. The initial values are set from the  defaults .   We recommand you to read the source code (straighforward) to check what you may be able to change.", 
            "title": "Overview"
        }, 
        {
            "location": "/configurations/#async-http-client", 
            "text": "\"HttpClientStore\" (singleton) stores a pair of default embedded fast/slow AsyncHttpClient, and another pair of customized fast/slow AsyncHttpClient. By default the pair of customized ones are just refereces (same as) the embedded ones.  When you submit a ParallelTask, if you do not set a specific AsyncHttpClient for this session, the default one is the Embedded fast.   You may set your customized client:   Just for one task or a session: when submit the task, setAsyncHttpClient() with your own context/parameters  Want to change for all the sessions, you can still do the above way every time you submit the task. Or you could call the following to set the default to be your own customized client to avoid setting it everytime.    HttpClientStore.getInstance().setCustomClientFast(yourClient);\n HttpClientStore.getInstance().setHttpClientTypeCurrentDefault(HttpClientType.CUSTOM_FAST);", 
            "title": "Async HTTP Client"
        }, 
        {
            "location": "/configurations/#timeout", 
            "text": "Connection / Request Timeout, as these are parameters from the Async HTTP Client, you will need to either change them in the global config or replace it in   timeoutInManagerSec and  actorMaxOperationTimeoutSec respectively, controls if the AHC or SSH/TCP/Ping client does not timeout, the actor level timeout in manager (for parallel task) and in the worker.", 
            "title": "Timeout"
        }, 
        {
            "location": "/configurations/#reduce-verbose-logs", 
            "text": "If you find the logs are chatty, please check the global config, there are parameters related to how to reduce the interval.  Current logic is always log first the first K% and the last K% percent, for those in the middle, will log based on the interval. You may overwrite these before submit a ParallelTask.  Also, you may change the log level as a whole.      /** The log response interval. */\n    public static int logResponseInterval = 1;\n\n    /** The log all response after percent. */\n    public static double logAllResponseAfterPercent = 95.0;\n\n    /** The log all response before percent. */\n    public static double logAllResponseBeforePercent = 5.0;\n\n    /** The log all response before init count. */\n    public static int logAllResponseBeforeInitCount = 2;\n\n    /** The log all response if total less than. */\n    public static int logAllResponseIfTotalLessThan = 11;", 
            "title": "Reduce Verbose Logs"
        }, 
        {
            "location": "/faq/", 
            "text": "FAQ \n Future Work\n\n\nFrequently Asked Questions\n\n\nImport and Setup\n\n\nQ: Why Eclipse has an error related to the \"@Override\" annotation ?\n\n\nA:\n Please set the compiler level 1.6+ in pom.xml\n\n\n    \nbuild\n\n        \npluginManagement\n\n            \nplugins\n\n                \nplugin\n\n                    \ngroupId\norg.apache.maven.plugins\n/groupId\n\n                    \nartifactId\nmaven-compiler-plugin\n/artifactId\n\n                    \nconfiguration\n\n                        \nsource\n1.6\n/source\n\n                        \ntarget\n1.6\n/target\n\n                    \n/configuration\n\n                \n/plugin\n\n            \n/plugins\n\n        \n/pluginManagement\n\n    \n/build\n\n\n\n\n\nQ: What JDK has you tested Parallec with ?\n\n\nA:\n We tested it with JDK 6 7 8.\n\n\nUsage\n\n\nQ: How to view logs ?\n\n\nA:\n Yes. \n\n\n\n\nParallec Log: we use slf4j + logback with rotation. Location is in \"parallec_logs\"\n\n\nParallelTask result log: can be turned on with \nParallelTaskBuilder.setAutoSaveLogToLocal()\n, by default this is turned off.\n\n\n\n\nQ: Do you support retries ?\n\n\nA:\n \n\n\n\n\nAsync Http Client supports \nretry\n with config.  \n\n\nFrom our experience, retrying on a ParallelTask is insufficient as 1% of the failed hosts will keep on retrying, slowing the whole task down. The right way would be 1 time try on all host, then collect those failed one, and then try again on these failed ones.\n\n\n\n\nQ: Do you have plans to update the versions of Async Http Client?\n\n\nA:\n We have not been able to use AHC version 1.9.x due to an issue with client auth.  Last year with some performance testing, we found more CPU usage and less speed after upgrade from AHC 1.65 to AHC 1.8.14 . We need to do more performance testing before the upgrade.\n\n\nQ: The logs are too chatty/verbose, can I disable or reduce them?\n\n\nA:\n Please refer to the configuration section on \"Reduce Verbose Logs\"\n\n\nFuture Work\n\n\nExtension to Other Protocols\n\n\nWith the framework and design, Expanding to other new protocols are fairly simple, with changes mostly to add a worker for this new protocol.\n\n\n\n\nAdd support for HTTP/2 or gPRC if needed.\n\n\nAdd support for SNMP protocols for network devices.\n\n\nEvaluate more performant implementations than JSch for SSH.", 
            "title": "FAQ & Future Work"
        }, 
        {
            "location": "/faq/#faq-future-work", 
            "text": "", 
            "title": "FAQ &amp; Future Work"
        }, 
        {
            "location": "/faq/#frequently-asked-questions", 
            "text": "Import and Setup  Q: Why Eclipse has an error related to the \"@Override\" annotation ?  A:  Please set the compiler level 1.6+ in pom.xml       build \n         pluginManagement \n             plugins \n                 plugin \n                     groupId org.apache.maven.plugins /groupId \n                     artifactId maven-compiler-plugin /artifactId \n                     configuration \n                         source 1.6 /source \n                         target 1.6 /target \n                     /configuration \n                 /plugin \n             /plugins \n         /pluginManagement \n     /build   Q: What JDK has you tested Parallec with ?  A:  We tested it with JDK 6 7 8.  Usage  Q: How to view logs ?  A:  Yes.    Parallec Log: we use slf4j + logback with rotation. Location is in \"parallec_logs\"  ParallelTask result log: can be turned on with  ParallelTaskBuilder.setAutoSaveLogToLocal() , by default this is turned off.   Q: Do you support retries ?  A:     Async Http Client supports  retry  with config.    From our experience, retrying on a ParallelTask is insufficient as 1% of the failed hosts will keep on retrying, slowing the whole task down. The right way would be 1 time try on all host, then collect those failed one, and then try again on these failed ones.   Q: Do you have plans to update the versions of Async Http Client?  A:  We have not been able to use AHC version 1.9.x due to an issue with client auth.  Last year with some performance testing, we found more CPU usage and less speed after upgrade from AHC 1.65 to AHC 1.8.14 . We need to do more performance testing before the upgrade.  Q: The logs are too chatty/verbose, can I disable or reduce them?  A:  Please refer to the configuration section on \"Reduce Verbose Logs\"", 
            "title": "Frequently Asked Questions"
        }, 
        {
            "location": "/faq/#future-work", 
            "text": "Extension to Other Protocols  With the framework and design, Expanding to other new protocols are fairly simple, with changes mostly to add a worker for this new protocol.   Add support for HTTP/2 or gPRC if needed.  Add support for SNMP protocols for network devices.  Evaluate more performant implementations than JSch for SSH.", 
            "title": "Future Work"
        }
    ]
}